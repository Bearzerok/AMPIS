{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True None\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "# test cuda\n",
    "import torch\n",
    "from torch.utils.cpp_extension import CUDA_HOME\n",
    "print(torch.cuda.is_available(), CUDA_HOME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2.utils.comm as comm\n",
    "from detectron2.checkpoint import DetectionCheckpointer, PeriodicCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "from detectron2.engine import default_argument_parser, default_setup, launch\n",
    "from detectron2.evaluation import (\n",
    "    CityscapesEvaluator,\n",
    "    COCOEvaluator,\n",
    "    COCOPanopticEvaluator,\n",
    "    DatasetEvaluators,\n",
    "    LVISEvaluator,\n",
    "    PascalVOCDetectionEvaluator,\n",
    "    SemSegEvaluator,\n",
    "    inference_on_dataset,\n",
    "    print_csv_format,\n",
    ")\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
    "from detectron2.utils.events import (\n",
    "    CommonMetricPrinter,\n",
    "    EventStorage,\n",
    "    JSONWriter,\n",
    "    TensorboardXWriter,)\n",
    "\n",
    "from detectron2.data import (\n",
    "    MetadataCatalog,\n",
    "    build_detection_test_loader,\n",
    "    build_detection_train_loader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = pathlib.Path('../data/raw/via_2.0.8/via_powder_particle_masks.json')\n",
    "with open(json_path, 'rb') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(name='powder_Training', thing_classes=[1, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetadataCatalog.get('powder_Training').set(**{'thing_classes': [1,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetadataCatalog.get('powder_Training').thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'a', 'Powder']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(labels, key=lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sc1Tile_001-001-000_0-000.png\n",
      "219\n",
      "Sc1Tile_001-002-000_0-000.png\n",
      "351\n",
      "Sc2Tile_001-001-000_0-000.png\n",
      "259\n",
      "Sc2Tile_010-006-000_0-000.png\n",
      "238\n",
      "Sc3Tile_008-007-000_0-000.png\n",
      "293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Powder'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set()\n",
    "for x in data['_via_img_metadata'].values():\n",
    "    print(x['filename'])\n",
    "    print(len(x['regions']))\n",
    "    for y in x['regions']:\n",
    "        labels.add(y['region_attributes']['Label'])\n",
    "\n",
    "labels       \n",
    "#data['_via_img_metadata']['image.png1371223']['regions'][0]['region_attributes']['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z', 'a', 'b', 'c']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(['b','c','a','Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'a', 'Powder']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.add('A')\n",
    "sorted(list(labels), key=lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dicts(json_path):\n",
    "    \"\"\"\n",
    "    Loads data in format consistent with detectron2.\n",
    "    Adapted from balloon example here:\n",
    "    https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5\n",
    "    \n",
    "    Inputs: \n",
    "      json_path: string or pathlib path to json file containing relevant annotations\n",
    "    \n",
    "    Outputs:\n",
    "      dataset_dicts: list(dic) of datasets compatible for detectron 2\n",
    "                     More information can be found at:\n",
    "                     https://detectron2.readthedocs.io/tutorials/datasets.html#\n",
    "    \"\"\"\n",
    "    json_path = os.path.join(json_path) # needed for path manipulations\n",
    "    with open(json_path) as f:\n",
    "        via_data = json.load(f)\n",
    "        \n",
    "    # root directory of images is given by relative path in json file\n",
    "    img_root = os.path.join(os.path.dirname(json_path), via_data['_via_settings']['core']['default_filepath'])\n",
    "    imgs_anns = via_data['_via_img_metadata']\n",
    "    \n",
    "    \n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "\n",
    "        filename = os.path.join(img_root, v[\"filename\"])\n",
    "        \n",
    "        # inefficient for large sets of images, read from json?\n",
    "        height, width = skimage.io.imread(filename).shape[:2]\n",
    "\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        record[\"dataset_class\"] = v['file_attributes']['Image Class']\n",
    "        \n",
    "        annos = v[\"regions\"]\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            # not sure why this was here, commenting it out didn't seem to break anything\n",
    "            #assert not anno[\"region_attributes\"] \n",
    "            anno = anno[\"shape_attributes\"]\n",
    "            \n",
    "            # polygon masks is list of polygon coordinates in format ([x0,y0,x1,y1...xn,yn]) as specified in\n",
    "            # https://detectron2.readthedocs.io/modules/structures.html#detectron2.structures.PolygonMasks\n",
    "            px = anno[\"all_points_x\"]\n",
    "            py = anno[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            \n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS, # boxes are given in absolute coordinates (ie not corner+width+height)\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "def split_data_dict(dataset_dicts, get_subset=None):\n",
    "    \"\"\"\n",
    "    Splits data from json into subsets (ie training/validation/testing)\n",
    "    \n",
    "    inputs \n",
    "      dataset_dicts- list(dic) from get_data_dicts()\n",
    "      get_subset- function that identifies \n",
    "                  class of each item  in dataset_dict.\n",
    "                  For example, get_subset(dataset_dicts[0])\n",
    "                  returns 'Training', 'Validation', 'Test', etc\n",
    "                  If None, default function is used\n",
    "    \n",
    "    returns\n",
    "      subs- dictionary where each key is the class of data\n",
    "            determined from get_subset, and value is a list\n",
    "            of dicts (same format of output of get_data_dicts())\n",
    "            with data of that class\n",
    "    \"\"\"\n",
    "    \n",
    "    if get_subset is None:\n",
    "        get_subset = lambda x: x['dataset_class']\n",
    "    \n",
    "    \n",
    "    subsets = np.unique([get_subset(x) for x in dataset_dicts])\n",
    "\n",
    "    datasets = dict(zip(subsets, [[] for _ in subsets]))\n",
    "    \n",
    "    for d in dataset_dicts:\n",
    "        datasets[get_subset(d)].append(d)\n",
    "    \n",
    "    return datasets\n",
    "    \n",
    "\n",
    "# TODO setup 'thing_classes' to read from data-- later, this requires a lot of changes\n",
    "\n",
    "json_path = '../data/raw/via_2.0.8/via_powder_particle_masks.json'\n",
    "ddicts = get_data_dicts(json_path)\n",
    "\n",
    "subs = split_data_dict(ddicts)\n",
    "\n",
    "for key, value in subs.items():\n",
    "    DatasetCatalog.register(\"powder_\" + key, lambda key=key: subs.get(key))\n",
    "    MetadataCatalog.get(\"powder_\" + key).set(thing_classes=[\"Powder\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######### uncomment to visualize\n",
    "\n",
    "print('training')\n",
    "for d in DatasetCatalog.get('powder_Training'):\n",
    "    img = cv2.imread(str(d[\"file_name\"]))\n",
    "    visualizer = Visualizer(img, metadata=MetadataCatalog.get('powder_Training'), scale=1)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    fig, ax = plt.subplots(figsize=(10,5), dpi=300)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    plt.show()\n",
    "print('validation')\n",
    "for d in DatasetCatalog.get('powder_Validation'):\n",
    "    img = cv2.imread(str(d[\"file_name\"]))\n",
    "    visualizer = Visualizer(img, metadata=MetadataCatalog.get('powder_Training'), scale=1)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    fig, ax = plt.subplots(figsize=(10,5), dpi=300)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"powder_Training\",)\n",
    "cfg.DATASETS.TEST = (\"powder_Validation\")\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.MODEL_WEIGHTS = '../models/model_final_f10217.pkl'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (powder particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict = subs['Training'][0]\n",
    "ddict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.dataset_mapper import DatasetMapper\n",
    "mapper = DatasetMapper(cfg)\n",
    "mapped_ddict = mapper(ddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_ddict['instances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_ddict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATASETS.TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataval\n",
    "data_val = dataval.build_detection_val_loader(cfg, None, ['powder_Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = build_detection_train_loader(cfg)\n",
    "data_val_loader = build_detection_test_loader(cfg, 'powder_Validation')\n",
    "\n",
    "for x in data_loader:\n",
    "    print(x[0].keys())\n",
    "    print(type(x[0]['instances']))\n",
    "    print(dir(x[0]['instances']))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??model_zoo.get_checkpoint_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
