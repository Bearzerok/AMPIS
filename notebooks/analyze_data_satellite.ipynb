{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import detectron2\n",
    "import torch\n",
    "import mrcnn_utils\n",
    "import mrcnn_visualize\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import skimage.io\n",
    "\n",
    "import seaborn as sns\n",
    "import skimage.measure\n",
    "\n",
    "import evaluate\n",
    "import analyze\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_ = 'satellite'\n",
    "\n",
    "gt_root = pathlib.Path('../data/raw/via_2.0.8/via_satellite_masks.json')\n",
    "pred_root = pathlib.Path('../data/interim/satellite_predictions_outputs_np.pickle')\n",
    "\n",
    "assert gt_root.is_file()\n",
    "assert pred_root.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pred_root, 'rb') as f:\n",
    "    pred_data = pickle.load(f)\n",
    "\n",
    "pred_instances = [analyze.instance_set().read_from_numpy_out(\n",
    "    x,y,True) for x, y in pred_data.items()]\n",
    "    \n",
    "    \n",
    "gt_instances = [analyze.instance_set().read_from_ddict(x, True)\n",
    "             for x in analyze.get_data_dicts(gt_root)]\n",
    "\n",
    "gt_instances = [{x.filepath.name: x for x in gt_instances}[f] \n",
    "                for f in pred_data] # hacky but this rearranges \n",
    "                # the order of the instances so both sets are the same\n",
    "                # the dictionary maps filenames to the gt instances\n",
    "                # f in pred_data  iterates through ordered filenames\n",
    "                # stored as keys in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "gt = gt_instances[-1]\n",
    "\n",
    "# predicted\n",
    "pred = pred_instances[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "colors = evaluate.random_colors(len(gt.class_idx), 32)\n",
    "mrcnn_visualize.display_instances(gt.img, gt.boxes, gt.masks, \n",
    "                                  gt.class_idx, [''], colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original mask predictions \n",
    "\n",
    "pcolors = evaluate.random_colors(len(pred.class_idx), 34)\n",
    "mrcnn_visualize.display_instances(gt.img, pred.boxes, pred.masks, \n",
    "                                  pred.class_idx, [''], colors=pcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for predset, label in zip([pred_instances,],\n",
    "                         ['pred',]):\n",
    "    results[label] = []\n",
    "    for gt, pred in zip(gt_instances, predset):\n",
    "        results[label].append(analyze.mask_match_stats(gt.masks, \n",
    "                                               pred.masks))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_precision = [x['match_precision'] for x in results['pred']]\n",
    "match_recall = [x['match_recall'] for x in results['pred']]\n",
    "\n",
    "mask_precision = [x['mask_precision'] for x in results['pred']]\n",
    "mask_recall = [x['mask_recall'] for x in results['pred']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Train {}'.format(x) for x in range(1, 9)]\n",
    "files.extend(['Validation {}'.format(x) for x in range(1, 3)]) \n",
    "files_list = []\n",
    "[files_list.extend(files) for _ in range(2)]\n",
    "\n",
    "\n",
    "y = np.concatenate((match_precision, \n",
    "                    match_recall,), axis=0)\n",
    "\n",
    "x = []\n",
    "[x.extend([i]*10) for i in ['precision', 'recall', ]]\n",
    "\n",
    "df_match = pd.DataFrame()\n",
    "\n",
    "df_match['files'] = files_list\n",
    "df_match['y'] = y\n",
    "df_match['x'] = x\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,3), dpi=300)\n",
    "sns.barplot(x=\"x\", y=\"y\",  hue='files', data=df_match, ax=ax)\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "ax.set_ylabel('match precision or recall')\n",
    "ax.set_xlabel('')\n",
    "xlims = ax.get_xlim()\n",
    "ax.plot(xlims, [1,1], '--k', linewidth=1)\n",
    "ax.set_xlim(xlims)\n",
    "ax.set_ylim([0.5,1.01])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((mask_precision, mask_recall, ), axis=0)\n",
    "\n",
    "newx = []\n",
    "newy = []\n",
    "newfiles = []\n",
    "\n",
    "for xi, yi, file in zip(x, y, files_list):\n",
    "    for yii in yi:\n",
    "        newx.append(xi)\n",
    "        newy.append(yii)\n",
    "        newfiles.append(file)\n",
    "df_mask = pd.DataFrame()\n",
    "\n",
    "df_mask['files'] = newfiles\n",
    "df_mask['y'] = newy\n",
    "df_mask['x'] = newx\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,3), dpi=300)\n",
    "#box = ax.get_position()\n",
    "#ax.set_position([0,0,box.width,box.height])\n",
    "sns.boxplot(x=\"x\", y=\"y\",  hue='files', data=df_mask, \n",
    "            ax=ax, showfliers=False)\n",
    "l1 = ax.legend(bbox_to_anchor=(1.0,1.0))\n",
    "ax.set_ylabel('mask precision or recall')\n",
    "ax.set_xlabel('')\n",
    "xlims = ax.get_xlim()\n",
    "ax.plot(xlims, [1,1], '--k', linewidth=1)\n",
    "ax.set_xlim(xlims)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_instances[-1]\n",
    "gt = gt_instances[-1]\n",
    "masks, boxes, colors, colormap = analyze.match_visualizer(gt.masks, gt.boxes,\n",
    "                                  pred.masks, pred.boxes,)\n",
    "\n",
    "mrcnn_visualize.display_instances(gt.img, boxes, masks, \n",
    "                                  np.zeros(len(boxes), np.int), [''], colors=colors)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for i, name in enumerate(['TP','FP','FN']):\n",
    "    ax.bar(-1000-i, 4+i, color=colormap[name], label=name)\n",
    "    \n",
    "ax.axis([0,10,0,10])\n",
    "ax.legend(fontsize=16)\n",
    "ax.set_title('legend for image plot')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, colormap = analyze.mask_visualizer(gt.masks, pred.masks)\n",
    "bbox = np.asarray([(0,0,*masks.shape[:2]) for _ in range(masks.shape[2])])\n",
    "\n",
    "img = gt.img.copy()\n",
    "colors = sns.color_palette(n_colors=7)\n",
    "colors[1] = [1,0,0]\n",
    "colors[2] = [0,1,0]\n",
    "colors[3] = [0.8, 0.8, 0.8]\n",
    "\n",
    "for i, (mask, color) in enumerate(zip(np.transpose(masks, (2,0,1)), colors)):\n",
    "    img = mrcnn_visualize.apply_mask(img, mask, color)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,10), dpi=300)\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for i in range(7):\n",
    "    ax.bar(-1000-i, 4+i, color=colors[i], label=colormap[1][i+1])\n",
    "    \n",
    "ax.axis([0,10,0,10])\n",
    "ax.legend(fontsize=16)\n",
    "ax.set_title('legend for image plot')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data=False\n",
    "if save_data:\n",
    "    for iset, name in zip([gt_instances, pred_instances], ['gt', 'pred']):\n",
    "        with open('../data/interim/instance_sets/{}_{}_instance_sets.pickle'.format(dataset_name, name), 'wb') as f:\n",
    "            pickle.dump(iset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
