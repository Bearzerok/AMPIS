{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dicts(json_path):\n",
    "    \"\"\"\n",
    "    Loads data in format consistent with detectron2.\n",
    "    Adapted from balloon example here:\n",
    "    https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5\n",
    "    \n",
    "    Inputs: \n",
    "      json_path: string or pathlib path to json file containing relevant annotations\n",
    "    \n",
    "    Outputs:\n",
    "      dataset_dicts: list(dic) of datasets compatible for detectron 2\n",
    "                     More information can be found at:\n",
    "                     https://detectron2.readthedocs.io/tutorials/datasets.html#\n",
    "    \"\"\"\n",
    "    json_path = pathlib.Path(json_path) # needed for path manipulations\n",
    "    with open(json_path) as f:\n",
    "        via_data = json.load(f)\n",
    "        \n",
    "    # root directory of images is given by relative path in json file\n",
    "    img_root = pathlib.Path(json_path.parent, via_data['_via_settings']['core']['default_filepath'])\n",
    "    imgs_anns = via_data['_via_img_metadata']\n",
    "    \n",
    "    \n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "\n",
    "        filename = pathlib.Path(img_root, v[\"filename\"])\n",
    "        \n",
    "        # inefficient for large sets of images, read from json?\n",
    "        height, width = skimage.io.imread(filename).shape[:2]\n",
    "\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        record[\"dataset_class\"] = v['file_attributes']['Image Class']\n",
    "        \n",
    "        annos = v[\"regions\"]\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            # not sure why this was here, commenting it out didn't seem to break anything\n",
    "            #assert not anno[\"region_attributes\"] \n",
    "            anno = anno[\"shape_attributes\"]\n",
    "            \n",
    "            # polygon masks is list of polygon coordinates in format ([x0,y0,x1,y1...xn,yn]) as specified in\n",
    "            # https://detectron2.readthedocs.io/modules/structures.html#detectron2.structures.PolygonMasks\n",
    "            px = anno[\"all_points_x\"]\n",
    "            py = anno[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            \n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS, # boxes are given in absolute coordinates (ie not corner+width+height)\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "def split_data_dict(dataset_dicts, get_subset=None):\n",
    "    \"\"\"\n",
    "    Splits data from json into subsets (ie training/validation/testing)\n",
    "    \n",
    "    inputs \n",
    "      dataset_dicts- list(dic) from get_data_dicts()\n",
    "      get_subset- function that identifies \n",
    "                  class of each item  in dataset_dict.\n",
    "                  For example, get_subset(dataset_dicts[0])\n",
    "                  returns 'Training', 'Validation', 'Test', etc\n",
    "                  If None, default function is used\n",
    "    \n",
    "    returns\n",
    "      subs- dictionary where each key is the class of data\n",
    "            determined from get_subset, and value is a list\n",
    "            of dicts (same format of output of get_data_dicts())\n",
    "            with data of that class\n",
    "    \"\"\"\n",
    "    \n",
    "    if get_subset is None:\n",
    "        get_subset = lambda x: x['dataset_class']\n",
    "    \n",
    "    \n",
    "    subsets = np.unique([get_subset(x) for x in dataset_dicts])\n",
    "\n",
    "    datasets = dict(zip(subsets, [[] for _ in subsets]))\n",
    "    \n",
    "    for d in dataset_dicts:\n",
    "        datasets[get_subset(d)].append(d)\n",
    "    \n",
    "    return datasets\n",
    "    \n",
    "\n",
    "# TODO setup 'thing_classes' to read from data-- later, this requires a lot of changes\n",
    "\n",
    "json_path = '../data/raw/via_2.0.8/via_powder_particle_masks.json'\n",
    "ddicts = get_data_dicts(json_path)\n",
    "\n",
    "subs = split_data_dict(ddicts)\n",
    "\n",
    "for key, value in subs.items():\n",
    "    DatasetCatalog.register(\"powder_\" + key, lambda key=key: subs.get(key))\n",
    "    MetadataCatalog.get(\"powder_\" + key).set(thing_classes=[\"Powder\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs['Training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DatasetCatalog.get('powder_Validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(name='powder_Training', thing_classes=['Powder'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetadataCatalog.get('powder_Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Powder']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetadataCatalog.get('powder_Training').get('thing_classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######### uncomment to visualize\n",
    "\n",
    "# print('training')\n",
    "# for d in DatasetCatalog.get('powder_Training'):\n",
    "#     img = cv2.imread(str(d[\"file_name\"]))\n",
    "#     visualizer = Visualizer(img, metadata=MetadataCatalog.get('powder_Training'), scale=1)\n",
    "#     vis = visualizer.draw_dataset_dict(d)\n",
    "#     fig, ax = plt.subplots(figsize=(10,5), dpi=300)\n",
    "#     plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "#     plt.show()\n",
    "# print('validation')\n",
    "# for d in DatasetCatalog.get('powder_Validation'):\n",
    "#     img = cv2.imread(str(d[\"file_name\"]))\n",
    "#     visualizer = Visualizer(img, metadata=MetadataCatalog.get('powder_Training'), scale=1)\n",
    "#     vis = visualizer.draw_dataset_dict(d)\n",
    "#     fig, ax = plt.subplots(figsize=(10,5), dpi=300)\n",
    "#     plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
